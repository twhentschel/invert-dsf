---
jupytext:
  formats: ipynb,md:myst
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.15.2
kernelspec:
  display_name: Python 3 (ipykernel)
  language: python
  name: python3
---

# Optimize collision rate model for known Average Atom collision rate data

We use collision rate data from an average atom model to produce Mermin ELF data.
We then try to fit a Mermin ELF model using our collision rate model to the data.
This is different from notebook `4.0-twh-optimize-known-collisions.txt` because 
the collision rate that produced the data comes from an independent/black-box 
collision rate model.

The goal with this notebook is to highlight the flexibility of our own collision
rate model.

```{code-cell} ipython3
# Load the "autoreload" extension so that code can change
%load_ext autoreload

# always reload modules so that as you change code in src, it gets loaded
%autoreload 2
```

```{code-cell} ipython3
import numpy as np
from scipy import optimize
import matplotlib.pyplot as plt
from functools import partial

import jax
import jax.numpy as jnp
import jax.scipy.stats as stats

import emcee 
from multiprocessing import Pool

from uegdielectric import ElectronGas
from uegdielectric.dielectric import Mermin

from src.inference.collision_models import collision_activate_decay
from src.inference.mcmc_inference import unique_hdf5_group
from src.utilities import collrateimag, AtomicUnits, elec_loss_fn

import warnings
warnings.filterwarnings('ignore')

jax.config.update("jax_enable_x64", True)
```

# Define collision rate model

```{code-cell} ipython3
# define our collision rate function
def collisionrate(freq, params):
    # real part
    recollision = collision_activate_decay(freq, *params)
    # imaginary part
    imcollision = collrateimag(recollision)

    return recollision + 1j * imcollision
```

# Get the data

```{code-cell} ipython3
datafile = "../../data/external/Al-1 _vwf.txt"
# just copying from the data file
# temperature
teV = 1
t = teV / AtomicUnits.energy

# density
d_ang = 0.18071 # 1/[angstroms]**3
d = d_ang * AtomicUnits.length**3

datadump = np.loadtxt(datafile, skiprows=9, usecols=[0, 5, 6, 9], unpack=True)
freq_data = datadump[0] # [eV]
print(f"length of data = {len(freq_data)}")
collrate_data = datadump[1] + 1j * datadump[2]
dos_data = datadump[3]

# function for true collision rate
true_collrate_fn = lambda x : np.interp(x, freq_data / AtomicUnits.energy, collrate_data)
# function for DOS ratio
dos_fn = lambda x : np.interp(x, freq_data / AtomicUnits.energy, dos_data)

# Wavenumber is independent of data -- can pick whatever we want to create our ELF data
wavenum_val = 0.7 / AtomicUnits.length # 1/[angstrom]
```

### Create ELF data with collision rate data

We will also trim down the number of data points.

```{code-cell} ipython3
# Reduce the amount of data we are considering
freq_data_trim = freq_data[::8]

elf_data = elec_loss_fn(Mermin(ElectronGas(t, d, dos_fn)),
                        wavenum_val * AtomicUnits.length,
                        freq_data_trim / AtomicUnits.energy,
                        true_collrate_fn
                       )
print(elf_data.shape)
```

### plot the collision rate data

```{code-cell} ipython3
plt.semilogx(freq_data_trim, true_collrate_fn(freq_data_trim / AtomicUnits.energy).real, label="real")
plt.plot(freq_data_trim, true_collrate_fn(freq_data_trim / AtomicUnits.energy).imag, label="imag.")
plt.xlabel(r"$\omega$ [eV]")
plt.ylabel("collision frequency [au]")
plt.legend()
```

# Define residual function for optimizing the parameters

This is a first step before doing Bayesian inference

```{code-cell} ipython3
def residual_fn(x, y, dielectricfn, wavenum, collisionfn, params):
    """ 
    x: frequency data points corresponding to output data `y`
    y: ELF data points
    dielectricfn: dielectric function, a function of `wavenum` and `freq`
    wavenum: wave number value(s)
    freq: array of frequency values
    collisionfn: function for collision rate, depends on `freq` and the
        parameters `params` we want to optimize
    params (tuple): parameters that go into collision rate model `collisionfn`
    
    returns:
        residual of the model with respect to the data `y`
    """
    elf_calc = elec_loss_fn(dielectricfn,
                            wavenum,
                            x,
                            lambda x: collisionfn(x, params))
    return y - elf_calc
```

# Optimize to get initial guess for parameters

```{code-cell} ipython3
# setup
residual = partial(residual_fn,
                   freq_data_trim / AtomicUnits.energy,
                   elf_data,
                   Mermin(ElectronGas(t, d, dos_fn)),
                   wavenum_val * AtomicUnits.length,
                   collisionrate
                  )
# initial parameter guesses
initparams = (0, 1, 0, 1, 1.5, 0, 10)

# optimization results
optresult = optimize.least_squares(residual, initparams, max_nfev=150)
```

```{code-cell} ipython3
optresult
```

Plot true collision frequencies and the optimized versions

```{code-cell} ipython3
# original
plt.semilogx(freq_data_trim, true_collrate_fn(freq_data_trim / AtomicUnits.energy).real, c="C3", label="Avg. Atom")
plt.plot(freq_data_trim, true_collrate_fn(freq_data_trim / AtomicUnits.energy).imag, c="C3", ls="--")
# optimized
plt.plot(freq_data_trim, collisionrate(freq_data_trim / AtomicUnits.energy, optresult.x).real, c="C0", label="opt.")
plt.plot(freq_data_trim, collisionrate(freq_data_trim / AtomicUnits.energy, optresult.x).imag, c="C0", ls="--")
plt.xlabel(r"$\omega$ [eV]")
plt.ylabel("collision frequency [au]")
plt.legend()
```

```{code-cell} ipython3
plt.semilogx(freq_data_trim, elf_data, c="C3", label="Avg. Atom")
opt_elf = elec_loss_fn(Mermin(ElectronGas(t, d, dos_fn)),
                       wavenum_val * AtomicUnits.length,
                       freq_data_trim / AtomicUnits.energy,
                       lambda x: collisionrate(x, optresult.x)
                      )
plt.plot(freq_data_trim, opt_elf, c="C0", ls='-.', label="opt.")
plt.ylabel("ELF [au]")
plt.xlabel(r"$\omega$ [eV]")
plt.ylim(1e-6) # resolution of data
plt.legend()
```

```{code-cell} ipython3
plt.loglog(freq_data_trim, elf_data, c="C3", label="Avg. Atom")
opt_elf = elec_loss_fn(Mermin(ElectronGas(t, d, dos_fn)),
                       wavenum_val * AtomicUnits.length,
                       freq_data_trim / AtomicUnits.energy,
                       lambda x: collisionrate(x, optresult.x)
                      )
plt.plot(freq_data_trim, opt_elf, c="C0", ls='-.', label="opt.")
plt.ylabel("ELF [au]")
plt.xlabel(r"$\omega$ [eV]")
plt.ylim(1e-6) # resolution of data
plt.legend()
```

# Perform MCMC

+++

The collision rate model we are using has parameters that don't run over the whole real line. For example, the `*_height` keyword argument in our parameters dictionary should be strictly positive. Additionally, other arguments like the location of the Drude peaks or the sigmoid function can have wildly varying magnitudes (see the data above). It's in our best interest when performing MCMC sampling to actually work with the log of each of these parameters, and transform back in post processing.

+++

Define our prior probability density function (pdf), likelihood, and posterior pdf

```{code-cell} ipython3
def logprior(logparams, limits=(-5,5)):
    """
    Uniform prior for the (log of the) parameters

    logparams: array_like
        logarithms of the parameters of collision frequency model
    limits: array_like of length 2
        limits of the uniform distribution, same for all parameters
    """
    logparams = np.asarray(logparams)
    # check that values are within limits
    if np.all(limits[0] < logparams) and np.all(logparams < limits[1]):
        return 0.0
    return -np.inf
    
def loglikelihood(logparams, x, y, dielectricfn, wavenum, collisionfn, cutoff=1):
    """
    log likelihood function that is the log of an N-dimensional cut-off
    function with soft (exponential) sides.

    logparams (array_like): parameters that go into collision rate model
    x: frequency data points corresponding to output data `y`
    y: ELF data points
    dielectricfn: dielectric function, a function of `wavenum` and `freq`
    wavenum: wave number value(s)
    freq: array of frequency values
    collisionfn: function for collision rate, depends on `freq` and `params`
    hyperparams (dict): keyword arguments for the hyperparameters of the
        likelihood function.
    
    returns:
        log likelihood evaluated for the given parameters at the input `x`.
    """
    if cutoff <= 0:
        raise RuntimeError("cutoff must be positive and nonzero")
        
    params = np.exp(logparams)
    residual = residual_fn(x,
                           y,
                           dielectricfn,
                           wavenum,
                           collisionfn,
                           params
                          )
        
    loglik = -np.max((residual / (np.sqrt(2) * cutoff))**2)
    
    return loglik

def logposterior_fn(logparams, x, y, dielectricfn, wavenum, collisionfn, priorhyperparams={}, likhyperparams={}):
    """
    log posterior pdf.

    x: frequency data points corresponding to output data `y`
    y: ELF data points
    dielectricfn: dielectric function, a function of `wavenum` and `freq`
    wavenum: wave number value(s)
    freq: array of frequency values
    collisionfn: function for collision rate, depends on `freq` and (the exponential of) `logparams`
    logparams: the logarithms of the parameters for `collisionfn`
    likhyperparams (dict): keyword arguments for the hyperparameters of the
        prior function.
    likhyperparams (dict): keyword arguments for the hyperparameters of the
        likelihood function.
    
    returns:
        log posterior function that only depends on params of collision rate
        model.
    """
    lgprior = logprior(logparams, **priorhyperparams)
    lglik = loglikelihood(logparams,
                          x, 
                          y, 
                          dielectricfn, 
                          wavenum, 
                          collisionfn, 
                          **likhyperparams
                         )
    
    if not (np.isfinite(lgprior) and np.isfinite(lglik)):
        return -np.inf
        
    return lgprior + lglik
```

```{code-cell} ipython3
# def logprior(params):
#     """
#     Uniform prior for the parameters

#     params: array_like
#         Parameters of collision frequency model
#     limits: array_like of length 2
#         limits of the uniform distribution, same for all parameters
#     """
#     # check that values are within limits
#     inbounds n d a r i es[0] < 10 and \\
#                0 < params[1] < 5 and \\
#                0 < params[2] < 10 and \\
#                0 < params[3] < 5 and \\
#                -2 < params[4] < 5 and \\
#                0 < params[5] < 10 and \\
#                0 < params[6] < 1e2
                
#     if inbounds:
#         return 0.0
#     return -np.inf
    
# def loglikelihood(params, x, y, dielectricfn, wavenum, collisionfn, cutoff=1):
#     """
#     log likelihood function that is the log of an N-dimensional cut-off
#     function with soft (exponential) sides.

#     params (array_like): parameters that go into collision rate model
#     x: frequency data points corresponding to output data `y`
#     y: ELF data points
#     dielectricfn: dielectric function, a function of `wavenum` and `freq`
#     wavenum: wave number value(s)
#     freq: array of frequency values
#     collisionfn: function for collision rate, depends on `freq` and `params`
#     hyperparams (dict): keyword arguments for the hyperparameters of the
#         likelihood function.
    
#     returns:
#         log likelihood evaluated for the given parameters at the input `x`.
#     """
#     if cutoff <= 0:
#         raise RuntimeError("cutoff must be positive and nonzero")

#     residual = residual_fn(x,
#                            y,
#                            dielectricfn,
#                            wavenum,
#                            collisionfn,
#                            params
#                           )
        
#     loglik = -np.max((residual / (np.sqrt(2) * cutoff))**2)
    
#     return loglik

# def logposterior_fn(params, x, y, dielectricfn, wavenum, collisionfn, priorhyperparams={}, likhyperparams={}):
#     """
#     log posterior pdf.

#     x: frequency data points corresponding to output data `y`
#     y: ELF data points
#     dielectricfn: dielectric function, a function of `wavenum` and `freq`
#     wavenum: wave number value(s)
#     freq: array of frequency values
#     collisionfn: function for collision rate, depends on `freq` and (the exponential of) `logparams`
#     params: parameters for `collisionfn`
#     likhyperparams (dict): keyword arguments for the hyperparameters of the
#         prior function.
#     likhyperparams (dict): keyword arguments for the hyperparameters of the
#         likelihood function.
    
#     returns:
#         log posterior function that only depends on params of collision rate
#         model.
#     """
#     lgprior = logprior(params, **priorhyperparams)
#     lglik = loglikelihood(params,
#                           x, 
#                           y, 
#                           dielectricfn, 
#                           wavenum, 
#                           collisionfn, 
#                           **likhyperparams
#                          )
    
#     if not (np.isfinite(lgprior) and np.isfinite(lglik)):
#         return -np.inf
        
#     return lgprior + lglik
```

```{code-cell} ipython3
lik_cutoff = 0.05
prior_lims = (-5, 3)

def logposterior(logparams):
    """
    Helper function for logposterior that treats all but the `logparams` argument as global
    variables.

    Doing it this way (as opposed to a lambda function, for example) because we need to
    pickle it for multiprocessing (see emcee docs).
    """
    return logposterior_fn(logparams,
                           freq_data_trim / AtomicUnits.energy,
                           elf_data,
                           Mermin(ElectronGas(t, d, dos_fn)),
                           wavenum_val * AtomicUnits.length,
                           collisionrate,
                           priorhyperparams = {"limits": prior_lims},
                           likhyperparams = {"cutoff": lik_cutoff}
                          )
```

## Run the MCMC sampler

We will use the results from the optimization to initialize the Markov chains.

```{code-cell} ipython3
import h5py
from datetime import datetime

samplesfile = "mcmc_AAcollisions"
dataset = "mcmc_samples"
runinfo = {
    "date" : datetime.today().strftime('%a %d %b %Y, %I:%M%p'),
    "input data info" : f"""Data generated using Average Atom 
         collisions [T-matrix cross sections, nonideal DOS, QOZ structure
         factors, LB form, inelastic processes], from file {samplesfile}""",
    "input data temperature [eV]" : teV,
    "input data density [1/angstrom^3]" : d_ang,
    "input data wavenumber [1/angstrom]" : wavenum_val,
    "collision rate model" : "collision_activate_decay",
    "likelihood function" : f"Soft (expenonential) cutoff with a cutoff value of {lik_cutoff}",
    "prior distribution function" : f"Uniform distribution with boundaries ({prior_lims})"
}

# sampler properties
ndim = len(optresult.x)
numchains = 14
numsamples = 3_000

# # avoid overwriting datasets
# dataset = unique_hdf5_group(samplesfile, dataset)
backend = emcee.backends.HDFBackend(samplesfile, name=dataset)
backend.reset(numchains, ndim)

# randomly initialize chains within the boundaries (log scale: prior_lims)
rng = np.random.default_rng()
initial_states = prior_lims[0] + (prior_lims[1] - prior_lims[0]) * rng.random(size=(numchains, ndim))

# perform ensemble MCMC sampling of logposterior
with Pool() as pool:
    sampler = emcee.EnsembleSampler(
        numchains, ndim, logposterior, backend=backend, pool=pool
    )
    sampler.run_mcmc(initial_states, numsamples, progress=True)

# add information to h5py file
with h5py.File(samplesfile, "a") as f:
    dset = f[dataset]
    for k, v in runinfo.items():
        dset.attrs[k] = v
```

```{code-cell} ipython3
with h5py.File(samplesfile, "a") as f:
    print(list(f.keys()))
    dset = f["mcmc_samples"]
    for attr in dset.attrs:
        print(f"{attr} : {dset.attrs[attr]}")
```

```{code-cell} ipython3
tau = backend.get_autocorr_time(tol=0)
burnin = int(2 * np.max(tau))
thin = int(0.5 * np.min(tau))
flat_samples = backend.get_chain(discard=burnin, flat=True, thin=thin)

print("Mean autocorrelation time: {0:.3f} steps".format(np.mean(tau)))
print("burn-in: {0}".format(burnin))
print("thin: {0}".format(thin))
print("flat chain shape: {0}".format(flat_samples.shape))
print("Mean acceptance fraction: {0:.3f}".format(np.mean(backend.accepted / backend.iteration)))
```

```{code-cell} ipython3
plt.close()
paramnames = (
    "drude_center",
    "drude_height",
    "gendrude_center",
    "gendrude_height",
    "gendrude_power",
    "logistic_activate",
    "logistic_gradient"
)
fig, axes = plt.subplots(ndim, figsize=(10,2.5*5), sharex=True)
samples = sampler.get_chain()
for i in range(ndim):
    ax = axes[i]
    # transform back to normal values (working with the log of the params)
    ax.plot(np.exp(samples[:,:,i]), 'k', alpha=0.3)
    #ax.set_xlim(0, len(samples))
    ax.set_ylabel(f"{paramnames[i]}")
    ax.yaxis.set_label_coords(-0.1, 0.5)

axes[-1].set_xlabel("step number");
```

```{code-cell} ipython3
sampler.get_chain().shape
```

```{code-cell} ipython3
plt.close()
# plot only a subset of marginal posterior distributions
fig, axes = plt.subplots(4, figsize=(10,2.5*4))
flat_samples = sampler.get_chain(discard=500, thin=24, flat=True)
print(flat_samples.shape)
for axi, i in enumerate([0, 3, 6, 9]):
    ax = axes[axi]
    ax.hist(flat_samples[:,i], bins=100, color='k', histtype="step")
    ax.set_ylabel(r'$p(\alpha_{{{}}})$'.format(i))
    ax.set_xlabel(r'$\alpha_{{{}}}$'.format(i))
    ax.set_yticks([]);
    # Percentiles
    mcmc = np.percentile(flat_samples[:, i], [16, 50, 84])
    q = np.diff(mcmc)

    ax.axvline(mcmc[0], c='C1', label='16%')
    ax.axvline(mcmc[1], c='C0', label='50%')
    ax.axvline(mcmc[2], c='C2', label='84%')

axes[0].legend()
plt.tight_layout()
```
