---
jupytext:
  formats: ipynb,md:myst
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.16.0
kernelspec:
  display_name: Python 3 (ipykernel)
  language: python
  name: python3
---

# Inference on TDDFT DSF data

Up until now, we have only considered inference on ELF data _generated by the Mermin ELF model_ using either external collision frequency data (from an average-atom model) or directly from our collision frequency model. In this notebook, we look at inferring the dynamic collision frequency from _external_ DSF data computed from TD-DFT simulations.

Now, it's possible that our Mermin model + collision frequency model will not be express enough to describe the TDDFT data, so we will experiment fitting to specific ranges around the peak in the data. Additionally, we won't have a true collision frequency to compare our inference results to. We will only know that accuracy of our results based on the quality of the Mermin model fit to the ELF data itself.

We will experiment with using both average-atom computed density of dtates and ideal density of states to define the Mermin ELF model.

```{code-cell} ipython3
# Load the "autoreload" extension so that code can change
%load_ext autoreload

# always reload modules so that as you change code in src, it gets loaded
%autoreload 2
```

```{code-cell} ipython3
import numpy as np
rng = np.random.default_rng()
import matplotlib.pyplot as plt
from scipy import optimize
from datetime import datetime
import h5py

import emcee 
from uegdielectric import ElectronGas
from uegdielectric.dielectric import Mermin

from src.inference.collision_models import BornLogPeak
from src.inference.mcmc_inference import inference_loop, flat_mcmc_samples
from src.utilities import AtomicUnits, elec_loss_fn
import src.inference.probability_models as prob

import warnings
warnings.filterwarnings('ignore')
```

Define the conditions of the material and wave number

```{code-cell} ipython3
AAdatafile = "../../data/external/Al-1 _vwf.txt"
# temperature
teV = 1
t = teV / AtomicUnits.energy

# density
d_ang = 0.18071 # 1/[angstroms]**3
d = d_ang * AtomicUnits.length**3

# chemical potential
cp = 0.3212 # [at u]

# ionization state (at T = 1 eV)
Z = 3

# # read in data
# AAdata = np.loadtxt(AAdatafile, skiprows=9, usecols=[0, 9], unpack=True)

# # function for DOS ratio
# dos_fn = lambda x : np.interp(x, np.sqrt(2 * AAdata[0] / AtomicUnits.energy), AAdata[1])

# electron data
electrons = ElectronGas(t, d)

# dielectric function
dielectric = Mermin(electrons)

# Wavenumber is independent of data -- can pick whatever we want to create our ELF data
wavenum = 1.55 # 1/[angstrom]
```

# Define collision frequency model

```{code-cell} ipython3
# define our collision frequency function
collisionfreq = BornLogPeak(electrons.temperature, electrons.density, electrons.chemicalpot, Z)
```

# Define the ELF model

using the Mermin dielectric function and the `collisionfreq` function

```{code-cell} ipython3
def elfmodel(freq, params):
    return elec_loss_fn(
        dielectric,
        wavenum * AtomicUnits.length,
        freq,
        lambda x: collisionfreq(x, params)
    )
```

# Get the TD-DFT DSF data for the correct wave number and convert it to the ELF

```{code-cell} ipython3
DFTdatafile = "../../data/external/Al_MD_1eV_DSF_more_qs.txt"
dftfreq, dftdsf = np.loadtxt(DFTdatafile, usecols=[0, 3], unpack=True)
# create log frequency grid
freq_grid = np.geomspace(1e-1, 1e3, 300) # [eV]
# linear interpolate DSF data on the log grid and convert to atomic units
dsf_interp = np.interp(freq_grid, dftfreq, dftdsf) * AtomicUnits.energy


# convert the DSF to an ELF
elf_full_data = (
    dsf_interp
    * 4 
    * np.pi**2  
    * d
    / Z
    / (wavenum * AtomicUnits.length)**2 
    * (1 - np.exp(-(freq_grid / AtomicUnits.energy) / t))
)

# truncate range to focus only on peak of ELF
percentage_of_peak = 0.99
threshold = (1 - percentage_of_peak) * np.max(elf_full_data)
mask = (elf_full_data > threshold) & (freq_grid > 3)

freq_data = freq_grid[mask]
elf_data = elf_full_data[mask]

plt.plot(freq_grid, elf_full_data, c="red", label="TD-DFT (log-grid)", lw=2)
plt.plot(freq_data, elf_data, lw=2, c="black")
plt.ylabel("ELF [au]")
plt.xlabel(r"$\hbar\omega$ [eV]")
plt.legend()
# plt.axhline(threshold, ls="--", c="gray")
plt.xlim(0, 50)
plt.ylim(0, 1.2)
print(f"length of data = {freq_data.shape}")
```

# Define residual function for ELF data

We also mask the relative residual so it only considers the peaks in the data.
Finally, we do a least squares fit of the ELF model to the ELF data by varying the parameters of the collision frequency model.

```{code-cell} ipython3
residualtype = "abs"
# setup
def residual(params):
    return prob.residual(
        elfmodel, freq_data / AtomicUnits.energy, elf_data, params, weight = residualtype
    )

def objective(params):
    return np.linalg.norm(residual(params))
    
# initial parameter guesses
initparams = (1, 1, 1, 1, 1)

# optimization results
bounds = [[0, 0, 0, 1e-1, 0], [5, 9.9, 1.4, 50, 4]]

optresult = optimize.least_squares(residual, initparams, bounds=bounds, max_nfev=150)
# bounds = [(1e-2, 5), (1e-2, 4.9), (1e-2, 5), (1e-2, 10), (1e-2, 5)]
# optresult = optimize.shgo(objective, bounds) 
```

```{code-cell} ipython3
optresult
```

```{code-cell} ipython3
# optimized
plt.semilogx(freq_data, collisionfreq(freq_data / AtomicUnits.energy, optresult.x).real, c="C0", label="opt.", lw=3)
plt.plot(freq_grid, collisionfreq(freq_grid / AtomicUnits.energy, optresult.x).real, c="C0", ls="--")
plt.plot(freq_grid, collisionfreq(freq_grid / AtomicUnits.energy, initparams).real, c="C3", label="init.")
plt.plot(freq_grid, collisionfreq(freq_grid / AtomicUnits.energy, optresult.x).imag, c="C2", ls="--")
plt.xlabel(r"$\hbar\omega$ [eV]")
plt.ylabel("collision freq [au]")
plt.legend()
```

```{code-cell} ipython3
plt.plot(freq_data, elf_data, label="TD-DFT")
opt_elf = elfmodel(freq_data / AtomicUnits.energy, optresult.x)
plt.plot(freq_data, opt_elf, label="opt.", ls="--")
# plt.plot(freq_data, elfmodel(freq_data / AtomicUnits.energy, initparams), label="init.", ls="--")
plt.plot(freq_data, np.zeros_like(freq_data), "k.")
plt.ylabel("ELF [au]")
plt.xlabel(r"$\hbar \omega$ [eV]")
plt.legend()
```

# Perform MCMC

Define a (log) posterior distribution that only depends on the parameters of the collision frequency model

```{code-cell} ipython3
lik_sigma = 0.1
prior_lims = [
    [0, 0.2],
    [0, 5],
    [0, 1.5],
    [1e-1, 10],
    [0, 4]
]


logprior = prob.UniformLogPrior(prior_lims)
loglikelihood = prob.SquaredExpLogLikelihood(
    elf_data,
    freq_data / AtomicUnits.energy,
    elfmodel,
    lik_sigma,
    residualweight = residualtype
)
logposterior = prob.LogPosterior(logprior, loglikelihood)
logposterior(optresult.x)
```

## Run the MCMC sampler

We will use the results from the optimization to initialize the Markov chains.

```{code-cell} ipython3
samplesfile = "../../data/mcmc/mcmc_tddft_singleq"
dataset = f"{residualtype} residual - q = {wavenum} - {percentage_of_peak}% peak threshold"
```

```{code-cell} ipython3
runinfo = {
    "date" : datetime.today().strftime('%a %d %b %Y, %I:%M%p'),
    "input data info" : f"""Linear-interpolated TD-DFT data.""",
    "input data temperature [eV]" : teV,
    "input data density [1/angstrom^3]" : d_ang,
    "input data wavenumber [1/angstrom]" : wavenum,
    "chemical potential [a.u.]" : electrons.chemicalpot,
    "frequency grid [eV]" : freq_grid,
    "frequency grid mask" : mask,
    "collision freq model" : "BornLogPeak, 5 parameters (inverse grad parameter)",
    # "likelihood function" : f"Soft (expenonential) cutoff with a cutoff value of {lik_cutoff}",
    "likelihood function" : f"Squared Exponential with a std. deviaton value of {lik_sigma}",
    "residual" : residualtype,
    "prior distribution function" : f"Uniform distribution with boundaries ({prior_lims})"
}

# sampler properties
ndim = 5 # number of parameters
numchains = 10
numsamples = 5_000
```

```{code-cell} ipython3
# randomly initialize chains within the boundaries
initial_state = optresult.x + 1e-4 * rng.random(size=(numchains, ndim))

# uncomment to run and potentially overwrite data
sampler = inference_loop(
    initial_state, 
    logposterior,
    numsamples, 
    samplesfile, 
    dataset, 
    runinfo, 
    overwrite=True
)
```

#### Read in MCMC data

```{code-cell} ipython3
# dataset = "rel residual - q = 1.55"
backend = emcee.backends.HDFBackend(samplesfile, name=dataset)
flat_samples = flat_mcmc_samples(backend)
```

```{code-cell} ipython3
# # discard first chain because it gets stuck
# samples = backend.get_chain(discard=3791, thin=620)[:, 1:, :]
# steps, chains, dims = samples.shape
# flat_samples = np.reshape(samples, (steps * chains, 4))
# flat_samples.shape
```

# MCMC results

## Markov chain tracings for each parameter

Note there are multiple chains being plotted for each parameter, showing their paths in parameter space.

```{code-cell} ipython3
paramnames = (
    "Born height",
    "Logistic height",
    "Logistic activate",
    "Logistic rise",
    "Logistic decay"
)
fig, axes = plt.subplots(ndim, figsize=(10,2.5*5), sharex=True)
samples = backend.get_chain()
for i in range(ndim):
    ax = axes[i]
    ax.plot(samples[:,:,i], 'k', alpha=0.3)
    #ax.set_xlim(0, len(samples))
    ax.set_ylabel(f"{paramnames[i]}")
    ax.yaxis.set_label_coords(-0.1, 0.5)

# step = int(samples.shape[0] / 100)
# samplesposterior = np.asarray([[logposterior(samples[i, j, :]) for j in range(samples.shape[1])] for i in range(0, samples.shape[0], step)])
# axes[-1].plot(np.arange(0, samples.shape[0], step), samplesposterior, 'k', alpha=0.3)
# axes[-1].plot(np.arange(0, samples.shape[0], step), np.mean(samplesposterior, axis=1), 'r', alpha=0.8)
# axes[-1].set_ylabel("log posterior")

axes[-1].set_xlabel("step number")
```

## Corner plot showing histograms of the samples from the posterior distribution

The posterior is 4-dimensional (4 parameters), but the corner plot shows 1D and 2D slices through the full distribution (i.e. marginal distributions). The blue-dashed line shows the mean of the samples.

```{code-cell} ipython3
import corner

fig = corner.corner(flat_samples, labels=paramnames)

# compute empirical mean of samples
mean = np.mean(flat_samples, axis=0)

corner.overplot_lines(fig, mean, linestyle="--", color="C0")
corner.overplot_points(fig, mean[np.newaxis], marker="o", linestyle="--", color="C0")
```

## Plot the collision frequency model using random samples of the parameters from MCMC

```{code-cell} ipython3
# randomly pick 100 samples from our MCMC sampling data
inds = rng.integers(len(flat_samples), size=50)
# plot collision function for different parameters from MCMC sampling
for ind in inds:
    sample = flat_samples[ind]
    plt.plot(
        freq_data,
        collisionfreq(freq_data / AtomicUnits.energy, sample).real,
        "C1",
        alpha=0.2
    )
    plt.loglog(
        freq_grid, 
        collisionfreq(freq_grid / AtomicUnits.energy, sample).real, 
        "grey", 
        alpha=0.1
    )
    # plt.semilogx(
    #     freq_grid, 
    #     collisionfreq(freq_grid / AtomicUnits.energy, sample).imag, 
    #     "C0", 
    #     alpha=0.1
    # )

plt.xlabel(r"$\hbar\omega$ [eV]")
plt.ylabel("collision freq [au]")
# plt.yscale('log')
# plt.savefig("../../reports/figures/mcmc_modeldata_collisionsamples")
```

## Plot the ELF model using random samples of the (collision frequency) parameters from MCMC

This uses the same random samples from the above plot.

```{code-cell} ipython3
# # plot ELF for different parameters from MCMC sampling
# for ind in inds:
#     sample = flat_samples[ind]
#     plt.semilogx(
#         freq_data,
#         elfmodel(freq_data / AtomicUnits.energy, sample), 
#         "C1", 
#         alpha=0.1
#     )
# # plot data
# plt.loglog(freq_data, elf_data, c="k", label="true ELF", lw=2, ls='--')

# plt.ylabel("ELF [au]")
# plt.xlabel(r"$\hbar\omega$ [eV]")
# plt.legend()
# # plt.savefig("../../reports/figures/mcmc_modeldata_ELFsamples")
```

```{code-cell} ipython3
# plot ELF for different parameters from MCMC sampling
for ind in inds:
    sample = flat_samples[ind]
    plt.plot(
        freq_data,
        elfmodel(freq_data/ AtomicUnits.energy, sample), 
        "C1", 
        alpha=0.2
    )
    plt.plot(
        freq_grid,
        elfmodel(freq_grid / AtomicUnits.energy, sample), 
        "grey", 
        alpha=0.1
    )
# plot data
plt.plot(freq_grid, elf_full_data, c="k", label="TDDFT ELF", lw=2, ls='--')
plt.xlim(0, 50)
plt.ylabel("ELF [au]")
plt.xlabel(r"$\hbar\omega$ [eV]")
plt.legend()
```

## Test sum rule

```{code-cell} ipython3
from scipy.integrate import quad
sample = flat_samples[inds[47]]
x = np.linspace(1e-6, 500, 3000)
y = elfmodel(x, sample)
elfsum = np.trapz(x * y, x)
sumrule = np.pi / 2 * (4 * np.pi * d)
print(f"integral = {elfsum}")
print(f"sum rule = {sumrule}")
```

```{code-cell} ipython3
def dosintegrand(x):
    dos = np.sqrt(2 * x) / np.pi**2
    f = 1 / (1 + np.exp((x - electrons.chemicalpot) / electrons.temperature))
    return dos * f
```

```{code-cell} ipython3
x = np.linspace(0, 4, 500)
y = dosintegrand(x)
print(f"temperature = {electrons.temperature} (at. u.)")
print(f"chemical potential = {electrons.chemicalpot} (at. u.)")
print(f"DOS integral = {np.trapz(y, x)}")
```

```{code-cell} ipython3

```
