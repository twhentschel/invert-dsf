---
jupytext:
  formats: ipynb,md:myst
  text_representation:
    extension: .md
    format_name: myst
    format_version: 0.13
    jupytext_version: 1.16.0
kernelspec:
  display_name: Python 3 (ipykernel)
  language: python
  name: python3
---

# Inference on TDDFT DSF data

Up until now, we have only considered inference on ELF data _generated by the Mermin ELF model_ using either external collision frequency data (from an average-atom model) or directly from our collision frequency model. In this notebook, we look at inferring the dynamic collision frequency from _external_ DSF data computed from TD-DFT simulations.

Now, it's possible that our Mermin model + collision frequency model will not be express enough to describe the TDDFT data, so we will experiment fitting to specific ranges around the peak in the data. Additionally, we won't have a true collision frequency to compare our inference results to. We will only know that accuracy of our results based on the quality of the Mermin model fit to the ELF data itself.

We will experiment with using both average-atom computed density of dtates and ideal density of states to define the Mermin ELF model.

```{code-cell} ipython3
# Load the "autoreload" extension so that code can change
%load_ext autoreload

# always reload modules so that as you change code in src, it gets loaded
%autoreload 2
```

```{code-cell} ipython3
import numpy as np
rng = np.random.default_rng()
import matplotlib.pyplot as plt
from scipy import optimize
from datetime import datetime
import h5py

import emcee 
from uegdielectric import ElectronGas
from uegdielectric.dielectric import Mermin

from src.inference.collision_models import collision_activate_decay, collision_activate_decay_imag
from src.inference.mcmc_inference import inference_loop, flat_mcmc_samples
from src.utilities import AtomicUnits, elec_loss_fn
import src.inference.probability_models as prob

import warnings
warnings.filterwarnings('ignore')
```

# Get average-atom DOS data

Also define the conditions of the material and wave number

```{code-cell} ipython3
AAdatafile = "../../data/external/Al-1 _vwf.txt"
# temperature
teV = 1
t = teV / AtomicUnits.energy

# density
d_ang = 0.18071 # 1/[angstroms]**3
d = d_ang * AtomicUnits.length**3

# chemical potential
cp = 0.3212 # [at u]

# ionization state (at T = 1 eV)
Z = 3

# read in data
AAdata = np.loadtxt(AAdatafile, skiprows=9, usecols=[0, 9], unpack=True)

# function for DOS ratio
dos_fn = lambda x : np.interp(x, np.sqrt(2 * AAdata[0] / AtomicUnits.energy), AAdata[1])

# electron data
electrons = ElectronGas(t, d)#, dos_fn, cp)

# dielectric function
dielectric = Mermin(electrons)

# Wavenumber is independent of data -- can pick whatever we want to create our ELF data
wavenum = 1.55 # 1/[angstrom]
```

# Define collision frequency model

```{code-cell} ipython3
# define our collision frequency function
def collisionfreq(freq, params):
    # real part
    recollision = collision_activate_decay(freq, *params)
    # imaginary part
    imcollision = collision_activate_decay_imag(freq, *params)

    return (recollision + 1j * imcollision)
```

# Define the ELF model

using the Mermin dielectric function and the `collisionfreq` function

```{code-cell} ipython3
def elfmodel(freq, params):
    return elec_loss_fn(
        dielectric,
        wavenum * AtomicUnits.length,
        freq,
        lambda x: collisionfreq(x, params)
    )
```

# Get the TD-DFT DSF data for the correct wave number and convert it to the ELF

```{code-cell} ipython3
DFTdatafile = "../../data/external/Al_MD_1eV_DSF_more_qs.txt"
dftfreq, dftdsf = np.loadtxt(DFTdatafile, usecols=[0, 3], unpack=True)
# create log frequency grid
freq_grid = np.geomspace(1e-1, 1e3, 200) # [eV]
# linear interpolate DSF data on the log grid and convert to atomic units
dsf_interp = np.interp(freq_grid, dftfreq, dftdsf) * AtomicUnits.energy

# # truncate and thin DFT data to about 100 points
# truncatemask = (10 < dftfreq) & (dftfreq < 70)
# thin_step = 15
# freq_data = dftfreq[truncatemask][::thin_step]
# # also convert DSF to atomic units
# dftdsf = dftdsf[truncatemask][::thin_step] * AtomicUnits.energy


# convert the DSF to an ELF
elf_full_data = (
    dsf_interp
    * 4 
    * np.pi**2  
    * d
    / Z
    / (wavenum * AtomicUnits.length)**2 
    * (1 - np.exp(-(freq_grid / AtomicUnits.energy) / t))
)

# truncate range to focus only on peak of ELF
percentage_of_peak = 0.85
threshold = (1 - percentage_of_peak) * np.max(elf_full_data)
mask = (elf_full_data > threshold) & (freq_grid > 10)

freq_data = freq_grid[mask]
elf_data = elf_full_data[mask]

plt.semilogx(freq_grid, elf_full_data, c="red", label="TD-DFT (log-grid)", lw=2)
plt.plot(freq_data, elf_data, lw=2, c="black")
plt.ylabel("ELF [au]")
plt.xlabel(r"$\hbar\omega$ [eV]")
plt.legend()
plt.xlim(5, 45)
plt.axhline(threshold, ls="--", c="gray")

print(f"length of data = {freq_data.shape}")
```

# Define residual function for ELF data

We also mask the relative residual so it only considers the peaks in the data.
Finally, we do a least squares fit of the ELF model to the ELF data by varying the parameters of the collision frequency model.

```{code-cell} ipython3
residualtype = "rel"
# setup
def residual(params):
    return prob.residual(
        elfmodel, freq_data / AtomicUnits.energy, elf_data, params, weight = residualtype
    )

def objective(params):
    return np.linalg.norm(residual(params))
    
# initial parameter guesses
initparams = [0.48647414, 0.06293753, 0.27164363, 8.66461154]

# optimization results
# optresult = optimize.least_squares(residual, initparams, bounds=(1e-2, 49), max_nfev=150)
bounds = [(1e-2, 50), ] * 4
optresult = optimize.dual_annealing(objective, bounds) 
```

```{code-cell} ipython3
optresult
```

```{code-cell} ipython3
# optimized

plt.plot(freq_data, collisionfreq(freq_data / AtomicUnits.energy, optresult.x).real, c="C0", label="opt.", lw=3)
plt.plot(freq_grid, collisionfreq(freq_grid / AtomicUnits.energy, optresult.x).real, c="C0", ls="--")
plt.plot(freq_grid, collisionfreq(freq_grid / AtomicUnits.energy, initparams).real, c="C3", label="init.")
plt.xlabel(r"$\hbar\omega$ [eV]")
plt.ylabel("collision freq [au]")
plt.xscale("log")
plt.legend()
```

```{code-cell} ipython3
plt.plot(freq_data, elf_data, label="TD-DFT")
opt_elf = elfmodel(freq_data / AtomicUnits.energy, optresult.x)
plt.plot(freq_data, opt_elf, label="opt.", ls="--")
#plt.plot(freq_data, elfmodel(freq_data / AtomicUnits.energy, initparams), label="init.", ls="--")
plt.plot(freq_data, 0.6 + np.zeros_like(freq_data), "k.")
plt.ylabel("ELF [au]")
plt.xlabel(r"$\hbar \omega$ [eV]")
plt.legend()
```

```{code-cell} ipython3
plt.loglog(freq_data, elf_data, label="TD-DFT")
plt.plot(freq_data, opt_elf, label="opt.", ls="--")
#plt.plot(freq_data, elfmodel(freq_data / AtomicUnits.energy, initparams), label="init.", ls="--")
plt.ylabel("ELF [au]")
plt.xlabel(r"$\hbar \omega$ [eV]")
plt.legend()
```

# Perform MCMC

Define a (log) posterior distribution that only depends on the parameters of the collision frequency model

```{code-cell} ipython3
lik_cutoff = 0.05
prior_lims = [
    [1e-3, 50],
    [1e-3, 50],
    [1e-3, 50],
    [1e-3, 50]
]

logprior = prob.UniformLogPrior(prior_lims)
loglikelihood = prob.SoftCutoffLogLikelihood(
    elf_data,
    freq_data / AtomicUnits.energy,
    elfmodel,
    lik_cutoff,
    residualweight = residualtype
)
logposterior = prob.LogPosterior(logprior, loglikelihood)
logposterior(optresult.x)
```

## Run the MCMC sampler

We will use the results from the optimization to initialize the Markov chains.

```{code-cell} ipython3
samplesfile = "../../data/mcmc/mcmc_tddft"
dataset = f"{residualtype} residual - q = {wavenum} - {percentage_of_peak}% peak threshold - ideal electrons"
```

```{code-cell} ipython3
runinfo = {
    "date" : datetime.today().strftime('%a %d %b %Y, %I:%M%p'),
    "input data info" : f"""Linear-interpolated TD-DFT data.""",
    "input data temperature [eV]" : teV,
    "input data density [1/angstrom^3]" : d_ang,
    "input data wavenumber [1/angstrom]" : wavenum,
    "frequency grid [eV]" : freq_grid,
    "frequency grid mask" : mask,
    "collision freq model" : "collision_activate_decay, 4 parameter",
    "likelihood function" : f"Soft (expenonential) cutoff with a cutoff value of {lik_cutoff}",
    "residual" : residualtype,
    "prior distribution function" : f"Uniform distribution with boundaries ({prior_lims})"
}

# sampler properties
ndim = 4 # number of parameters
numchains = 8
numsamples = 50_000
```

```{code-cell} ipython3
# randomly initialize chains within the boundaries
initial_state = optresult.x + 1e-4 * rng.random(size=(numchains, ndim))

# uncomment to run and potentially overwrite data
sampler = inference_loop(initial_state, logposterior, numsamples, samplesfile, dataset, runinfo, overwrite=False)
```

# Read in MCMC data

```{code-cell} ipython3
# dataset = "rel residual - q = 1.55"
backend = emcee.backends.HDFBackend(samplesfile, name=dataset)
flat_samples = flat_mcmc_samples(backend)

# with h5py.File(samplesfile, "a") as f:
#     print(list(f.keys()))
#     freq = f[dataset].attrs["frequency grid [eV]"]
#     dset = f[dataset]
#     for attr in dset.attrs:
#         if attr != "random_state_1":
#             print(f"{attr} : {dset.attrs[attr]}")
# print(freq)
# np.allclose(freq, freq_data)
```

```{code-cell} ipython3
# # discard first chain because it gets stuck
# samples = backend.get_chain(discard=3791, thin=620)[:, 1:, :]
# steps, chains, dims = samples.shape
# flat_samples = np.reshape(samples, (steps * chains, 4))
# flat_samples.shape
```

# MCMC results

## Markov chain tracings for each parameter

Note there are multiple chains being plotted for each parameter, showing their paths in the 4D parameter space.

```{code-cell} ipython3
plt.close()
paramnames = (
    "gen. Lorentzian height",
    "gen. Lorentzian power-law",
    "Logistic activate",
    "Logistic gradient"
)
fig, axes = plt.subplots(ndim, figsize=(10,2.5*5), sharex=True)
samples = backend.get_chain()
for i in range(ndim):
    ax = axes[i]
    ax.plot(samples[:,:,i], 'k', alpha=0.3)
    #ax.set_xlim(0, len(samples))
    ax.set_ylabel(f"{paramnames[i]}")
    ax.yaxis.set_label_coords(-0.1, 0.5)

# step = int(samples.shape[0] / 100)
# samplesposterior = np.asarray([[logposterior(samples[i, j, :]) for j in range(samples.shape[1])] for i in range(0, samples.shape[0], step)])
# axes[-1].plot(np.arange(0, samples.shape[0], step), samplesposterior, 'k', alpha=0.3)
# axes[-1].plot(np.arange(0, samples.shape[0], step), np.mean(samplesposterior, axis=1), 'r', alpha=0.8)
# axes[-1].set_ylabel("log posterior")

axes[-1].set_xlabel("step number")
```

## Corner plot showing histograms of the samples from the posterior distribution

The posterior is 4-dimensional (4 parameters), but the corner plot shows 1D and 2D slices through the full distribution (i.e. marginal distributions). The blue-dashed line shows the mean of the samples.

```{code-cell} ipython3
import corner

fig = corner.corner(flat_samples, labels=paramnames)

# compute empirical mean of samples
mean = np.mean(flat_samples, axis=0)

corner.overplot_lines(fig, mean, linestyle="--", color="C0")
corner.overplot_points(fig, mean[np.newaxis], marker="o", linestyle="--", color="C0")
```

## Plot the collision frequency model using random samples of the parameters from MCMC

```{code-cell} ipython3
# randomly pick 100 samples from our MCMC sampling data
inds = rng.integers(len(flat_samples), size=100)
x = np.geomspace(1e-1, 1e3, 200)
# plot collision function for different parameters from MCMC sampling
for ind in inds:
    sample = flat_samples[ind]
    plt.plot(
        x,
        collisionfreq(x / AtomicUnits.energy, sample).real,
        "grey",
        alpha=0.1
    )
    plt.semilogx(
        freq_data, 
        collisionfreq(freq_data / AtomicUnits.energy, sample).real, 
        "C1", 
        alpha=0.2
    )

plt.xlabel(r"$\hbar\omega$ [eV]")
plt.ylabel("collision freq [au]")
plt.ylim(0, 1)
# plt.savefig("../../reports/figures/mcmc_modeldata_collisionsamples")
```

## Plot the ELF model using random samples of the (collision frequency) parameters from MCMC

This uses the same random samples from the above plot.

```{code-cell} ipython3
# # plot ELF for different parameters from MCMC sampling
# for ind in inds:
#     sample = flat_samples[ind]
#     plt.semilogx(
#         freq_data,
#         elfmodel(freq_data / AtomicUnits.energy, sample), 
#         "C1", 
#         alpha=0.1
#     )
# # plot data
# plt.loglog(freq_data, elf_data, c="k", label="true ELF", lw=2, ls='--')

# plt.ylabel("ELF [au]")
# plt.xlabel(r"$\hbar\omega$ [eV]")
# plt.legend()
# # plt.savefig("../../reports/figures/mcmc_modeldata_ELFsamples")
```

```{code-cell} ipython3
# plot ELF for different parameters from MCMC sampling
for ind in inds:
    sample = flat_samples[ind]
    plt.plot(
        freq_grid,
        elfmodel(freq_grid/ AtomicUnits.energy, sample), 
        "grey", 
        alpha=0.1
    )
    plt.plot(
        freq_data,
        elfmodel(freq_data / AtomicUnits.energy, sample), 
        "C1", 
        alpha=0.2
    )
# plot data
plt.plot(freq_grid, elf_full_data, c="k", label="true ELF", lw=2, ls='--')

plt.xlim(5, 45)
plt.ylabel("ELF [au]")
plt.xlabel(r"$\hbar\omega$ [eV]")
plt.legend()
```

## Test sum rule

```{code-cell} ipython3
from scipy.integrate import quad
sample = flat_samples[inds[0]]
x = np.linspace(1e-6, 500, 3000)
y = elfmodel(x, sample)
elfsum = np.trapz(x * y, x)
sumrule = np.pi / 2 * (4 * np.pi * d)
print(f"integral = {elfsum}")
print(f"sum rule = {sumrule}")
```

```{code-cell} ipython3
electrons.chemicalpot
```

```{code-cell} ipython3

```
